---
content_type: page
description: This section provides materials for a lecture on Markov chains. It includes
  the list of lecture topics, lecture video, lecture slides, readings, recitation
  problems, recitation help videos, and a tutorial with solutions.
draft: false
learning_resource_types: []
ocw_type: CourseSection
parent_title: 'Unit III: Random Processes'
parent_type: CourseSection
parent_uid: a407050c-bd3a-de7c-ddf4-8a582ba1ed50
title: 'Lecture 16: Markov Chains - I'
uid: 8f3c76f8-cf51-30bb-1aea-bcdc51a3cfa3
---
« {{% resource_link 091b0bdf-2c56-e919-8e8d-1be1365e4db6 "Previous" %}} | {{% resource_link 6c61e0f1-a4af-4a3b-6a5b-478304353f11 "Next" %}} »

## Lecture Topics

{{< tableopen >}}{{< tbodyopen >}}{{< tropen >}}{{< tdopen >}}
{{< resource de1d3cd7-b9ea-6e27-1478-cda527a3a164 >}}
{{< tdclose >}}{{< tdopen >}}

- Checkout counter example
- Markov process definition
- n-step transition probabilities
- Classification of states

{{< tdclose >}}{{< trclose >}}{{< tbodyclose >}}{{< tableclose >}}

## Lecture Activities

- Watch the {{% resource_link 05b0fffd-1405-eeb9-bccf-9f8bb9076963 "Lecture 16 Video" %}} by Prof. Tsitsiklis (00:52:06)
- Review the {{% resource_link 290daad9-889b-bffb-3b9c-1c29f5028f98 "Lecture 16: Markov Chains - I Slides (PDF)" %}}
- Read Sections 7.1–7.2 in the textbook

## Recitation Problems and Recitation Help Videos

Review the recitation problems in the PDF file below and try to solve them on your own. Two of the problems have an accompanying video where a teaching assistant solves the same problem.

- {{% resource_link 2b7791fa-9513-a259-8344-99e4ca2fe856 "Recitation 18 Problems (PDF)" %}}
- {{% resource_link 935d4c27-c530-6305-cd41-93b97e923b1f "Recitation 18 Solutions (PDF)" %}}

### Recitation Help Videos

{{< tableopen >}}{{< theadopen >}}{{< tropen >}}{{< thopen >}}
PROBLEM #
{{< thclose >}}{{< thopen >}}
PROBLEM TITLE
{{< thclose >}}{{< thopen >}}
PROBLEM SOLVED BY
{{< thclose >}}{{< trclose >}}{{< theadclose >}}{{< tbodyopen >}}{{< tropen >}}{{< tdopen >}}
1
{{< tdclose >}}{{< tdopen >}}
{{% resource_link 4c4425e3-9efd-59e5-c753-d7651d6ad017 "Setting Up a Markov Chain" %}}
{{< tdclose >}}{{< tdopen >}}
Jimmy Li
{{< tdclose >}}{{< trclose >}}{{< tropen >}}{{< tdopen >}}
3
{{< tdclose >}}{{< tdopen >}}
{{% resource_link 5a276b44-71a0-6225-5003-8e1d09c1cc8b "Markov Chain Practice 1" %}}
{{< tdclose >}}{{< tdopen >}}
Qing He
{{< tdclose >}}{{< trclose >}}{{< tbodyclose >}}{{< tableclose >}}

## Tutorial Problems

Review the tutorial problems in the PDF file below and try to solve them on your own.

- {{% resource_link 04d75e73-4146-f20b-100d-3ff2e08b6d39 "Tutorial 9 Problems (PDF)" %}} Do ONLY Problems 1 and 2
- {{% resource_link 3a4e4612-40e7-fd3b-97d8-270dd2b1e6b9 "Tutorial 9 Solutions (PDF)" %}}

« {{% resource_link 091b0bdf-2c56-e919-8e8d-1be1365e4db6 "Previous" %}} | {{% resource_link 6c61e0f1-a4af-4a3b-6a5b-478304353f11 "Next" %}} »